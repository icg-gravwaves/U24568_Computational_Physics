{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a394405",
   "metadata": {},
   "source": [
    "# Identifying common elements in two large lists\n",
    "\n",
    "This interactive example demonstrates that is often important to use the right tool, or computational method, for the task at hand. \n",
    "\n",
    "An example of this is the problem I set the first years earlier this year:\n",
    "\n",
    "Write a function numpy_nested_sum, which takes as input two 1D numpy arrays (x and y) with lengths N and M respectively and computes the following sum:\n",
    "\n",
    "$\\sum_{i=0}^{N-1} \\sum_{j=0}^{M-1} \\left(x[i]^2 + y[j]^2 \\right)$\n",
    "\n",
    "Many of the students tried something like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e238c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sum(arrx, arry):\n",
    "    summ = 0\n",
    "    for i in range(len(arrx)):\n",
    "        for j in range(len(arry)):\n",
    "            summ += arrx[i]**2 + arry[i]**2\n",
    "    return summ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf92d12",
   "metadata": {},
   "source": [
    "This directly implements the question as written, but didn't pass the longest test case (due to timeout). Those students that remembered that they were also highly trained mathemeticians did some algebraic reordering and realised that this was equal to:\n",
    "\n",
    "$\\sum_{i=0}^{N-1} (M * x[i]^2) +  \\sum_{j=0}^{M-1} ( N * y[j]^2)$\n",
    "\n",
    "This is then coded as\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5515c175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sum(arrx, arry):\n",
    "    summ = 0\n",
    "    for i in range(len(arrx)):\n",
    "        summ += M * arrx[i]**2\n",
    "    \n",
    "    for j in range(len(arry)):\n",
    "        summ += N * arry[i]**2\n",
    "    return summ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5b4d1d",
   "metadata": {},
   "source": [
    "and the students got full marks. The hint in the function name (to call this *nested* sum), was a bit unfair of course. However, the principal here is the important one: How many operations do you actually need to do to get the necessary output? This is called \"complexity analysis\" in computing, this article has a lot more details on this:\n",
    "\n",
    "https://www.freecodecamp.org/news/big-o-notation-why-it-matters-and-why-it-doesnt-1674cfa8a23c/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a923f53",
   "metadata": {},
   "source": [
    "Let's consider a different problem:\n",
    "\n",
    "* Consider two large lists of integers. Identify integers which are in *both* lists\n",
    "\n",
    "First let's create the lists and then let's take a first stab at this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6bb78a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create our lists first - DO NOT change this code\n",
    "import numpy\n",
    "list_a = numpy.random.randint(0,10000000,size=[100000])\n",
    "list_b = numpy.random.randint(0,10000000,size=[100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4f98c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then let's write our first solution\n",
    "def identify_common_elements(list_1, list_2):\n",
    "    common_elements = []\n",
    "    # Let's just write a for loop, and for every element check if it's in list_2\n",
    "    for elem in list_1:\n",
    "        if elem in list_2:\n",
    "            common_elements.append(elem)\n",
    "    return common_elements\n",
    "\n",
    "# This seems like it should be fast, right??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e98821",
   "metadata": {},
   "source": [
    "As before, run timeit and lprof on this code to determine run-time and the slowest line. *Before* running lprof identify where you think the most time will be taken, in which line of the code. Were you right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1807c261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run timeit and lprun here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752dc2c9",
   "metadata": {},
   "source": [
    "Most of the time is spent determining if elem is in list 2, for every element. There are in total `O(N**2)` operations in this operation, where N is the length of the array. Specifically for each of the `N` elements in list 1 we have to check if any of the `N` elements in list 2 are the same. (There would be some special cases here, for example if the lists have a length of 1000000, but contained only integers between 0 and 10). \n",
    "\n",
    "Can we do better? How can we speed up the `elem in list_2` part of the code? How about this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6815d5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try that again\n",
    "def identify_common_elements_with_a_set(list_1, list_2):\n",
    "    # ALL I DO IS ADD THE FOLLOWING 1 LINE\n",
    "    list_2 = set(list_2)\n",
    "    common_elements = []\n",
    "    # Let's just write a for loop, and for every element check if it's in list_2\n",
    "    for elem in list_1:\n",
    "        if elem in list_2:\n",
    "            common_elements.append(elem)\n",
    "    return common_elements\n",
    "\n",
    "# This seems like it wouldn't be any faster, right??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e58033",
   "metadata": {},
   "source": [
    "Again use timeit and lprof to profile the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537bd6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run timeit and lprun here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573c0685",
   "metadata": {},
   "source": [
    "Think about why that happened?\n",
    "\n",
    "Sometimes optimisations in python aren't obvious, because a lot of the internal details can be hidden. A `set` and a `list` are similar but very different objects. On the face of it a `set` just contains a list of non-duplicated entries (So `set([1,1,2,3,4])` = `set([1,2,3,4])`). But because non-duplicate entries are not possible the set can check if an item is in the `set`*much* more quickly than you can check if an item is in a list ... Basically python implements a technique called a \"hash table\" https://en.wikipedia.org/wiki/Hash_table to decide quickly if an object is already in the set. Dictionaries use the same technique with their keys. (Also look up binary search tables as another interesting technique for this kind of thing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3450e22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One more try\n",
    "def identify_common_elements_with_two_sets(list_1, list_2):\n",
    "    list_1 = set(list_1)\n",
    "    list_2 = set(list_2)\n",
    "    return list(list_1 & list_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5217c197",
   "metadata": {},
   "source": [
    "Again profile this code, is it quicker than the previous version?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0daa4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run timeit and lprun here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e1a845",
   "metadata": {},
   "source": [
    "You can use the `&` operator to take the combination of the two lists. This results in a code with much fewer lines, but the overall cost is much the same. *Converting* a list to a set would be a non-negligible cost here, but if your input is already a set, and your output can be a set then this operation will be faster.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3852b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_a = set(list_a)\n",
    "set_b = set(list_b)\n",
    "%timeit set_a & set_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baec477d",
   "metadata": {},
   "source": [
    "Can we do even better and record integers that occur multiple times in both lists? This algorithm sorts the input and then walks through the sorted arrays looking for duplicates. The sorting is a `N log N` operation, and the walkthrough requires `O(N)` operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91539c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try that again\n",
    "def identify_common_elements_with_a_walk(list_1, list_2):\n",
    "    list_1 = sorted(list_1)\n",
    "    list_2 = sorted(list_2)\n",
    "    idx_1 = 0\n",
    "    idx_2 = 0\n",
    "    l1 = len(list_1)\n",
    "    l2 = len(list_2)\n",
    "    common_elements = []\n",
    "    curr_1 = list_1[idx_1]\n",
    "    curr_2 = list_2[idx_2]\n",
    "    while 1:\n",
    "        if curr_1 == curr_2:\n",
    "            common_elements.append(curr_1)\n",
    "            idx_1 += 1\n",
    "            if idx_1 == l1:\n",
    "                break\n",
    "            curr_1 = list_1[idx_1]\n",
    "            idx_2 += 1\n",
    "            if idx_2 == l2:\n",
    "                break\n",
    "            curr_2 = list_2[idx_2]\n",
    "        elif curr_1 < curr_2:\n",
    "            idx_1 += 1\n",
    "            if idx_1 == l1:\n",
    "                break\n",
    "            curr_1 = list_1[idx_1]\n",
    "        else:\n",
    "            idx_2 += 1\n",
    "            if idx_2 == l2:\n",
    "                break\n",
    "            curr_2 = list_2[idx_2]\n",
    "    return common_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebde9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run timeit and lprun here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0aa0e8d",
   "metadata": {},
   "source": [
    "For the data arrays we are considering this is not faster, even if the arrays are sorted before sending to the function. That's probably not surprising. The `&` method on the two sets would have implemented this if it were faster!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
