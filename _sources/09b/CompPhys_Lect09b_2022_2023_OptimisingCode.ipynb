{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jeLYubUSQ-J"
   },
   "source": [
    "# Techniques to profile and optimise python code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3HWIij1wSQ-L"
   },
   "source": [
    "A common complaint about python is that \"it's not as fast as C/C++/fortran/...\". For example this recent article from Simon Portegies Zwart (https://arxiv.org/pdf/2009.11295.pdf) claims that one should not use python because it is inefficient, and therefore more environmentally harmful.\n",
    "\n",
    "However, this statement was demonstrated to be untrue by Pierre Augier (see links from https://physicsworld.com/a/the-huge-carbon-footprint-of-large-scale-computing/). Augier argues that while python will be slower than other languages if one does not consider optimization (often not needed if you just want to test something, or do something quickly), for large-scale simulations it can be made to be faster than the implementations of Portegies Zwart's code in C/C++/fortran (https://github.com/paugier/nbabel).\n",
    "\n",
    "So how do we do this? It is normally possible to write python code that is just as fast as code written in a \"fast\" (compiled) language such as C. After all, python is written in C and contains a wealth of libraries, such as numpy, that actually use compiled C (and even fortran) code in some of the most time-sensitive places.\n",
    "\n",
    "I think its more accurate to say that its easier to write \"slow\" code in python, because it's often hard to see why some things are slow. To write code that *is* as fast as C does require a bit of understanding on how C actually works, but in most cases you can write code that is more than fast enough using the techniques shown here. In this lecture we will try to\n",
    "\n",
    "* Highlight some of the places where python code is often slow and demonstrate ways to speed it up\n",
    "* Demonstrate tools to \"profile\" python code, specifically to identify the functions, and lines, where the code is slowest\n",
    "\n",
    "As a supplement to this, there are occasionally cases where python doesn't cut it in terms of speed. With the availability of numpy, *such cases are rare*. In such instances you can turn to \"Cython\" which is basically a hybrid of python and C/C++. We will cover Cython at the end of this course. Note that large parts of scipy are actually written in Cython, and while it is still nowhere near as well used as Python itself, it is increasing in popularity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RpsV1D6YSQ-M"
   },
   "source": [
    "## Before we start\n",
    "\n",
    "Before we start we will need to use a couple of utilities to demonstrate some of the profiling techniques. The cell below demonstrates how to do this in sciserver or Google Colab. **If using Sciserver (or Google colab) just run the cell below**.\n",
    "\n",
    "**If not using sciserver or colab**: This might not be the right way to install these utilities. If you are using Anaconda (or Minconda or any other conda installed python) you will probably want to use the `conda` command shown below and commented out *instead*. This is normally run in a terminal window. I can try to help you install these on your own machine, but I do not know your particular setup, and do not use Windows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PEHo_I3zSQ-M",
    "outputId": "df3c8e8e-3213-452f-d109-d43e2aafb294"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting line_profiler\n",
      "  Downloading line_profiler-4.0.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (662 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m662.2/662.2 KB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: line_profiler\n",
      "Successfully installed line_profiler-4.0.3\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting memory_profiler\n",
      "  Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from memory_profiler) (5.9.4)\n",
      "Installing collected packages: memory_profiler\n",
      "Successfully installed memory_profiler-0.61.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install line_profiler\n",
    "!{sys.executable} -m pip install memory_profiler\n",
    "\n",
    "# conda install line_profiler\n",
    "# conda install memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IlQEUP3BSQ-N"
   },
   "outputs": [],
   "source": [
    "# Load the stuff we imported above\n",
    "%load_ext line_profiler\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrvEzhRQSQ-N"
   },
   "source": [
    "## An example\n",
    "\n",
    "Here's an example code which integrates\n",
    "\n",
    "$cos(x) \\times \\frac{1}{x} $\n",
    "\n",
    "from $x = 1$ to $x=1000$.\n",
    "\n",
    "We will do this by using the simple rectangular method for numerically integrating. https://en.wikipedia.org/wiki/Riemann_sum .... I know you all know the theory behind this, and how to code up such an example, as I taught it to you all in MATLAB last year!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dx_Zb94hSQ-N",
    "outputId": "f0b848f5-b141-4fc6-87d9-08ac28b39d7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.33743511454087033\n"
     ]
    }
   ],
   "source": [
    "# NOTE: We write this as a set of functions. Functions are better to isolate different parts of\n",
    "#       the code and to be able to check each component individually. Using a class and class methods\n",
    "#       to do this is also fine, and we mix both here to show this ... Might not be the most aesthetic\n",
    "#       way of doing this, though! However, this does serve as a reminder: Don't write long blocks of code\n",
    "#       split up into functions!\n",
    "import numpy\n",
    "import math\n",
    "\n",
    "def compute_cosx(tseries):\n",
    "    \"\"\"\n",
    "    Computes cos(t) for all values in tseries\n",
    "    \"\"\"\n",
    "    cosx = numpy.zeros(len(tseries))\n",
    "    for idx, tval in enumerate(tseries):\n",
    "        cosx[idx] = math.cos(tseries[idx])\n",
    "    return cosx\n",
    "\n",
    "def compute_invx(tseries):\n",
    "    \"\"\"\n",
    "    Computes 1/x for all values in tseries\n",
    "    \"\"\"\n",
    "    invx = numpy.zeros(len(tseries))\n",
    "    for idx, tval in enumerate(tseries):\n",
    "        invx[idx] = 1 / tseries[idx]\n",
    "    return invx\n",
    "\n",
    "def compute_seriesproduct(series1, series2):\n",
    "    \"\"\"\n",
    "    Multiplies each element in series1 with the corresponding element in series2.\n",
    "    This returns an array of the multiplied elements.\n",
    "    \"\"\"\n",
    "    # Ensure the two arrays are the same length\n",
    "    assert(len(series1)==len(series2))\n",
    "    seriessum = numpy.zeros(len(series1))\n",
    "    for idx in range(len(series1)):\n",
    "        seriessum[idx] = series1[idx] * series2[idx]\n",
    "    return seriessum\n",
    "\n",
    "def compute_seriessum(series):\n",
    "    \"\"\"\n",
    "    Computes the sum of all values in series\n",
    "    \"\"\"\n",
    "    sumvals = 0\n",
    "    for idx in range(len(series)):\n",
    "        sumvals = sumvals + series[idx]\n",
    "    return sumvals\n",
    "\n",
    "\n",
    "class Integrator():  \n",
    "    def generate_integral(self):\n",
    "        \"\"\"\n",
    "        Integral function goes here\n",
    "        \"\"\"\n",
    "        cosx = compute_cosx(self.tseries)\n",
    "        invx = compute_invx(self.tseries)\n",
    "        prod = compute_seriesproduct(cosx, invx)\n",
    "        summed_prod = compute_seriessum(prod)\n",
    "        return summed_prod * self.delta_t\n",
    "\n",
    "\n",
    "    def __init__(self, tmin, tmax, delta_t):\n",
    "        \"\"\"\n",
    "        Initializes the class and timeseries\n",
    "        \"\"\"\n",
    "        self.tmin = tmin\n",
    "        self.tmax = tmax\n",
    "        self.delta_t = delta_t\n",
    "        tseries = numpy.arange(self.tmin, self.tmax, self.delta_t)\n",
    "        # We shift tseries by delta_t / 2 to ensure that we are using the midpoint rule (see wikipedia page)\n",
    "        tseries = tseries + self.delta_t / 2.\n",
    "        self.tseries = tseries\n",
    "\n",
    "\n",
    "def main_function():\n",
    "    intgr = Integrator(1, 10000, 1./300.)\n",
    "    return intgr.generate_integral()\n",
    "\n",
    "print (main_function())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZghpPJrSQ-O"
   },
   "source": [
    "## Starting to understand the code\n",
    "\n",
    "Our first step in understanding the code is to time it. This can be done in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MLhmVKQwSQ-O",
    "outputId": "3ed5e585-8792-4884-fe64-481c5205cf3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.38 s ± 257 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit main_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dBG7KlwySQ-P"
   },
   "source": [
    "Timeit will run the code a number of times and take an average. How many times it runs the code depends on how long the code takes (though you can override these values). Here we can see that our code took approximately a second to run. If running this only once then this is of course trivial.\n",
    "\n",
    "**Important rule of optimising: Don't waste time optimising a block of code, unless it is slowing down your work ... If others are using your code, you must think about how they might use your code though, might it be a problem in the future? There are certainly some things in the code above that are unnecessarily slow, which can be made faster just by writing the code better in the first place**\n",
    "\n",
    "Let's assume though that we might need to run this code thousands of times (or hundreds of thousands of times). In that case let's see what we can do to make it faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dKOUyi7MSQ-P"
   },
   "source": [
    "## Profiling code\n",
    "\n",
    "Python and Jupyter notebooks have some neat tools for profiling code. Profiling means measuring how long the code takes to run individual blocks of code. Most profilers measure the fraction of time spent inside each individual *function*. Therefore splitting your code up into a number of different functions can help both in terms of making it easier to read and understand the code, but also in terms of understanding any bottlenecks.\n",
    "\n",
    "Below we run a built-in profiler on our code above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vxS8eWKlSQ-P",
    "outputId": "0d6f7e3d-0ab5-419c-8940-0eac0eb022ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "*** Profile printout saved to text file 'prun0'. \n",
      "         2999721 function calls in 4.832 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "   List reduced from 14 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    1.419    1.419    1.419    1.419 <ipython-input-2-9645487cbb32>:16(compute_invx)\n",
      "        1    1.296    1.296    1.579    1.579 <ipython-input-2-9645487cbb32>:7(compute_cosx)\n",
      "        1    1.062    1.062    1.062    1.062 <ipython-input-2-9645487cbb32>:25(compute_seriesproduct)\n",
      "        1    0.754    0.754    0.754    0.754 <ipython-input-2-9645487cbb32>:37(compute_seriessum)\n",
      "  2999700    0.281    0.000    0.281    0.000 {built-in method math.cos}\n",
      "        1    0.009    0.009    0.009    0.009 {built-in method numpy.arange}\n",
      "        1    0.004    0.004    0.013    0.013 <ipython-input-2-9645487cbb32>:59(__init__)\n",
      "        1    0.004    0.004    4.832    4.832 <ipython-input-2-9645487cbb32>:72(main_function)\n",
      "        3    0.002    0.001    0.002    0.001 {built-in method numpy.zeros}\n",
      "        1    0.000    0.000    4.832    4.832 <string>:1(<module>)\n"
     ]
    }
   ],
   "source": [
    "%prun -l 10 -q -T prun0 main_function()\n",
    "\n",
    "print(open('prun0', 'r').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WPNAzx_-SQ-P"
   },
   "source": [
    "The `tottime` entry is the amount of time spent within each function. We can see that the majority of time is spent computing `cos(x)`, `inv(x)` and doing the series product and sum.\n",
    "\n",
    "To introduce all of our profiling tools in one place, let's also look at line-by-line and memory profiling. We can use the following to run the code to produce line-by-line profiling information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SF1tN59ZSQ-P",
    "outputId": "b9d2ed6e-e724-4c28-b90d-92de0acfcb2c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%lprun` not found.\n"
     ]
    }
   ],
   "source": [
    "timeseries = numpy.arange(1.0,1000.,0.01)\n",
    "#compute_cosx(timeseries)\n",
    "\n",
    "%lprun -T lprof0 -f main_function main_function()\n",
    "\n",
    "print(open('lprof0', 'r').read())\n",
    "\n",
    "# And we can also profile the sub-functions, such as compute_cosx\n",
    "\n",
    "%lprun -T lprof0 -f compute_cosx compute_cosx(timeseries)\n",
    "\n",
    "print(open('lprof0', 'r').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39gIpdtUSQ-Q"
   },
   "source": [
    "Finally, although we will not use it in this class, we can also profile the *memory usage* of a function in the same way. Unfortunately this only works for functions written in an external file, so we need to dump our code to a file and then run it from the file. Here's an example of that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DoARX6ELSQ-Q",
    "outputId": "0caab86e-1595-476d-9d46-9ba09696cdda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mprun_demo.py\n"
     ]
    }
   ],
   "source": [
    "%%file mprun_demo.py\n",
    "import numpy\n",
    "def invx_demo(tseries):\n",
    "    \"\"\"\n",
    "    Computes 1/x for all values in tseries\n",
    "    \"\"\"\n",
    "    invx = 1 / tseries\n",
    "    return invx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wsur8uXJSQ-Q",
    "outputId": "5787740a-859c-42bb-e439-4a36de4d95d2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "PYDEV DEBUGGER WARNING:\n",
      "sys.settrace() should not be used when the debugger is being used.\n",
      "This may cause the debugger to stop working correctly.\n",
      "If this is needed, please check: \n",
      "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
      "to see how to restore the debug tracing back correctly.\n",
      "Call Location:\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/memory_profiler.py\", line 847, in enable\n",
      "    sys.settrace(self.trace_memory_usage)\n",
      "\n",
      "\n",
      "PYDEV DEBUGGER WARNING:\n",
      "sys.settrace() should not be used when the debugger is being used.\n",
      "This may cause the debugger to stop working correctly.\n",
      "If this is needed, please check: \n",
      "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
      "to see how to restore the debug tracing back correctly.\n",
      "Call Location:\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/memory_profiler.py\", line 850, in disable\n",
      "    sys.settrace(self._original_trace_function)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from mprun_demo import invx_demo\n",
    "timeseries = numpy.arange(1.0,10000.,0.01)\n",
    "\n",
    "%mprun -f invx_demo invx_demo(timeseries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qaI8UEcXSQ-Q"
   },
   "source": [
    "## Using these tools and information to speed things up\n",
    "\n",
    "Okay, now that we've understood the tools available to us. Let's try to see if we can't improve things. The first place where the code is slow is in the `compute_cosx` function. Here's a major rule in python optimization:\n",
    "\n",
    "* Avoid for loops wherever possible\n",
    "\n",
    "In this case rather than using a python for loop to compute `cos(x)` at every index, let's use numpy to compute it at all indexes in one call. Yes, internally it will still need to loop over all values of `x` at some point and compute `cos(x)` for each point, but this will happen deep in some compiled numpy routine. In short\n",
    "\n",
    "* Use numpy routines on vectors to avoid for loops where possible.\n",
    "\n",
    "So we can replace our `compute_cosx` function with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "shRIQESsSQ-Q"
   },
   "outputs": [],
   "source": [
    "def compute_cosx(tseries):\n",
    "    \"\"\"\n",
    "    Computes cos(t) for all values in tseries\n",
    "    \"\"\"\n",
    "    return numpy.cos(tseries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8EZs__1qSQ-Q"
   },
   "source": [
    "Note that running this *after* the block above just replaces this function, so we can just run our profiler again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jU5fpK0oSQ-Q",
    "outputId": "077f0e13-c1e8-418f-c269-6d354ad8f71e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "*** Profile printout saved to text file 'prun0'. \n",
      "         19 function calls in 3.131 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "   List reduced from 13 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    1.444    1.444    1.444    1.444 <ipython-input-2-9645487cbb32>:16(compute_invx)\n",
      "        1    1.068    1.068    1.068    1.068 <ipython-input-2-9645487cbb32>:25(compute_seriesproduct)\n",
      "        1    0.557    0.557    0.557    0.557 <ipython-input-2-9645487cbb32>:37(compute_seriessum)\n",
      "        1    0.047    0.047    0.047    0.047 <ipython-input-10-40c68ad4621a>:1(compute_cosx)\n",
      "        1    0.007    0.007    0.007    0.007 {built-in method numpy.arange}\n",
      "        1    0.005    0.005    0.012    0.012 <ipython-input-2-9645487cbb32>:59(__init__)\n",
      "        1    0.003    0.003    3.131    3.131 <ipython-input-2-9645487cbb32>:72(main_function)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method numpy.zeros}\n",
      "        1    0.000    0.000    3.131    3.131 <string>:1(<module>)\n",
      "        1    0.000    0.000    3.116    3.116 <ipython-input-2-9645487cbb32>:48(generate_integral)\n"
     ]
    }
   ],
   "source": [
    "%prun -l 10 -q -T prun0 main_function()\n",
    "\n",
    "print(open('prun0', 'r').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_6z88gKSQ-Q"
   },
   "source": [
    "Now we can see that quite a bit of time is being spent in the remaining 3 `compute_x` functions. Let's try optimizing these as well by replacing the for loops with numpy vectorized calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8beJqJoLSQ-R",
    "outputId": "49914b31-3013-4c83-dc26-a67b4d317aa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "*** Profile printout saved to text file 'prun0'. \n",
      "         16 function calls in 0.110 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "   List reduced from 15 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.072    0.072    0.072    0.072 <ipython-input-10-40c68ad4621a>:1(compute_cosx)\n",
      "        1    0.013    0.013    0.013    0.013 {built-in method numpy.arange}\n",
      "        1    0.010    0.010    0.010    0.010 <ipython-input-14-e2555c7ade69>:1(compute_invx)\n",
      "        1    0.008    0.008    0.020    0.020 <ipython-input-2-9645487cbb32>:59(__init__)\n",
      "        1    0.005    0.005    0.005    0.005 <ipython-input-14-e2555c7ade69>:7(compute_seriesproduct)\n",
      "        1    0.002    0.002    0.002    0.002 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "        1    0.000    0.000    0.109    0.109 <ipython-input-2-9645487cbb32>:72(main_function)\n",
      "        1    0.000    0.000    0.110    0.110 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.088    0.088 <ipython-input-2-9645487cbb32>:48(generate_integral)\n",
      "        1    0.000    0.000    0.110    0.110 {built-in method builtins.exec}\n"
     ]
    }
   ],
   "source": [
    "def compute_invx(tseries):\n",
    "    \"\"\"\n",
    "    Computes 1/x for all values in tseries\n",
    "    \"\"\"\n",
    "    return 1. / tseries\n",
    "\n",
    "def compute_seriesproduct(series1, series2):\n",
    "    \"\"\"\n",
    "    Multiplies each element in series1 with the corresponding element in series2.\n",
    "    This returns an array of the multiplied elements.\n",
    "    \"\"\"\n",
    "    # Ensure the two arrays are the same length\n",
    "    assert(len(series1)==len(series2))\n",
    "    return series1 * series2\n",
    "\n",
    "def compute_seriessum(series):\n",
    "    \"\"\"\n",
    "    Computes the sum of all values in series\n",
    "    \"\"\"\n",
    "    return series.sum()\n",
    "\n",
    "%prun -l 10 -q -T prun0 main_function()\n",
    "\n",
    "print(open('prun0', 'r').read())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1CfN4HUYSQ-R"
   },
   "source": [
    "The code is now limited be a vectorized computation of cos(x). Not easy to make that much faster! Now with these optimizations let's see how fast our code runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_wKX0-L9SQ-R",
    "outputId": "3d467102-a558-47c0-b1be-961b6568ecd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.1 ms ± 887 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit main_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8JpHuhXSQ-R"
   },
   "source": [
    "The code now runs *2 orders of magnitude* quicker. For loops over a large number of values can be very inefficient! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUZYPXStSQ-R"
   },
   "source": [
    "## Exercise 1\n",
    "\n",
    "The following cells contain examples of python code that are written using explicit for loops. Time these functions (using `timeit`) and rewrite the for loop using numpy calls. After rewriting, time the functions again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4CxtpGfESQ-R"
   },
   "outputs": [],
   "source": [
    "# EXERCISE 1.1 - Here also investigate the time taken to compute these two functions. Which is faster?\n",
    "# Why do you think this is?\n",
    "# Numpy is really inefficient when running on scalar values.\n",
    "import numpy, math\n",
    "\n",
    "def compute_sin_tseries():\n",
    "    tseries = numpy.arange(1, 10000, 1./100.)\n",
    "    sin_tseries = numpy.zeros(len(tseries))\n",
    "    for i in range(len(timeseries)):\n",
    "        sin_tseries[i] = numpy.sin(timeseries[i])\n",
    "    return sin_tseries\n",
    "\n",
    "def compute_sin_tseries2():\n",
    "    tseries = numpy.arange(1, 10000, 1./100.)\n",
    "    sin_tseries = numpy.zeros(len(tseries))\n",
    "    for i in range(len(timeseries)):\n",
    "        sin_tseries[i] = math.sin(timeseries[i])\n",
    "    return sin_tseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pa9HGxtsSQ-R"
   },
   "outputs": [],
   "source": [
    "# Solution to exercise 1.1 goes in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nnbskyKPSQ-R"
   },
   "outputs": [],
   "source": [
    "# EXERCISE 1.2\n",
    "import math, numpy\n",
    "\n",
    "def compute_exp_tseries():\n",
    "    tseries = numpy.arange(1, 10000, 1./100.)\n",
    "    exp_tseries = numpy.zeros(len(tseries))\n",
    "    for i in range(len(tseries)):\n",
    "        exp_tseries[i] = math.e ** tseries[i]\n",
    "    return exp_tseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XjHnwtw9SQ-R"
   },
   "outputs": [],
   "source": [
    "# Solution to exercise 1.2 goes in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_qaa9IYvSQ-R",
    "outputId": "95faad9e-94c6-4438-8d34-28a377f73b5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.  8.  4. 46.]\n",
      "[1005.97971962 1010.39164807 1003.76167116 ...  989.2619583  1002.88408881\n",
      "  988.24284929]\n"
     ]
    }
   ],
   "source": [
    "# EXERCISE 1.3 - Note that there are two for loops here. It is possible to collapse into one\n",
    "# single vectorized call, but simply removing one of the for loops will make the code both readable\n",
    "# and reasonably optimized. Feel free to try this for yourself, but it is *not at all* trivial\n",
    "import numpy as np\n",
    "\n",
    "def sum_2d_array_to_1d(input_data):\n",
    "    \"\"\"\n",
    "    This function takes as input a 2-dimensional array, for example:\n",
    "    [[0,1,2,3],\n",
    "     [2,2,2,2],\n",
    "     [1,1,1,1],\n",
    "     [10,11,12,13]]\n",
    "    \n",
    "    It should sum over each of the *rows* in turn and return the sum of each as a new array\n",
    "    \n",
    "    [6, 8, 4, 46]\n",
    "    \"\"\"\n",
    "    output = np.zeros(len(input_data), dtype=float)\n",
    "    for i in range(len(input_data)):\n",
    "        # Looping over each row\n",
    "        current_sum = 0\n",
    "        for j in range(len(input_data[i])):\n",
    "            # Looping over each element in each row, e.g. 10->11->12->13 if the bottom row\n",
    "            current_sum += input_data[i][j]\n",
    "        output[i] = current_sum\n",
    "    return output\n",
    "\n",
    "# Short example to test that it works\n",
    "input_data = numpy.array([[0,1,2,3],\n",
    "                          [2,2,2,2],\n",
    "                          [1,1,1,1],\n",
    "                          [10,11,12,13]])\n",
    "\n",
    "print(sum_2d_array_to_1d(input_data))\n",
    "\n",
    "# *This* is the large example to use timeit on and to make fast to run\n",
    "input_data = numpy.random.random(size=[2000,2000])\n",
    "print(sum_2d_array_to_1d(input_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xsHLBOTISQ-R"
   },
   "outputs": [],
   "source": [
    "# Solution to exercise 1.3 goes in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k5SUDAZ5SQ-S"
   },
   "outputs": [],
   "source": [
    "# EXERCISE 1.4\n",
    "\n",
    "# This example performs a cross-correlation (hmm, now where have we seen that before? Does this feel\n",
    "# like something that would be **very, very important** for the coursework??. Of course the unoptimized\n",
    "# code below would work .... I just think it would take about 2 hours *per run* on the coursework data.\n",
    "\n",
    "\n",
    "def compute_cross_correlation():\n",
    "    signal = numpy.random.random(1024)\n",
    "    data = numpy.random.random(1024*10)\n",
    "    cross_correlation = []\n",
    "    for i in range(len(data) - len(signal)):\n",
    "        curr_cross_corr = 0\n",
    "        for j in range(len(signal)):\n",
    "            curr_cross_corr += signal[j] * data[i+j]\n",
    "        cross_correlation.append(curr_cross_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5rJXj_4USQ-S"
   },
   "outputs": [],
   "source": [
    "# Solution to exercise 1.4 goes in here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIknE2leSQ-S"
   },
   "source": [
    "## Exercise 2 - Square digits (again)\n",
    "\n",
    "In the debugging lecture last year we showed an example of a [not working] code to do the following:\n",
    "\n",
    "* Consider a sequence of numbers a0, a1, ..., an, in which an element is equal to the sum of squared digits of the previous element. The sequence ends once an element that has already been in the sequence appears again. So that an = a0. Given the first element a0, find the length of the sequence.\n",
    "\n",
    "\n",
    "So for example if a0 = 16. `1**2 + 6**2 = 37` -> `3**2 + 7**2 = 58` -> `5**2 + 8**2 = 89` -> `8**2 + 9**2 = 145` -> `1**2 + 4**2 + 5**2 = 42` -> `4**2 + 2**2 = 20` -> `2**2 + 0**2 = 4` -> `4**2 = 16` We've already seen 16 so we stop here. The sequence is `[16,37,58,89,145,42,20,4,16]` which has a length of 9, return 9.\n",
    "\n",
    "The code that we used had some optimisations, but was not particularly clear. To try to understand it better let's write this out in a code that approaches the problem in a different way, with comments etc. to try to make it clearer what is going on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "En-oTKYuSQ-S",
    "outputId": "d778b2f4-fc8c-4f59-aca6-b4c32af82910"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "square_digits(103) gives: 4 \n",
      " Should be 4\n",
      "\n",
      "square_digits(612) gives: 16 \n",
      " Should be 16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def square_digits(input_number):\n",
    "\n",
    "    # Initialize by setting the list of outputs equal to the input\n",
    "    output_list = [input_number]\n",
    "    # And setting the last_number variable to the input\n",
    "    last_number = input_number\n",
    "\n",
    "    # This is basically a for-loop that will only exit when we explicitly say \"exit\"\n",
    "    while 1:\n",
    "        # Step one: We must identify the digits of last_number\n",
    "        # Cast to a string\n",
    "        last_number = str(last_number)\n",
    "        # And then convert to a list of integers. We do this using a list comprehension, which is powerful, but not fast\n",
    "        digits = [int(digit) for digit in last_number]\n",
    "        # So if last_number is 49120 then digits = [4,9,1,2,0]\n",
    "        \n",
    "        # We can then sum the digits squared using another list comprehension\n",
    "        # digits = [4,9,1,2,0] -> 16 + 81 + 1 + 4 = 102\n",
    "        digit_squared_sum = sum([digit*digit for digit in digits])\n",
    "        \n",
    "        # Is this value already in the list?\n",
    "        if digit_squared_sum in output_list:\n",
    "            # Add this value and then exist\n",
    "            output_list.append(digit_squared_sum)\n",
    "            break\n",
    "        else:\n",
    "            # Else add the value and then continue\n",
    "            output_list.append(digit_squared_sum)\n",
    "            last_number = digit_squared_sum\n",
    "\n",
    "    return len(output_list)\n",
    "\n",
    "print(\"square_digits(103) gives:\",square_digits(103), \"\\n Should be 4\")\n",
    "print()\n",
    "print(\"square_digits(612) gives:\",square_digits(612), \"\\n Should be 16\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fmuh0RmSSQ-S",
    "outputId": "bea573c8-06eb-4a02-dd2d-540cb0054c78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try it with the following\n",
    "very_long_integer = 2**100\n",
    "square_digits(very_long_integer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QmXoUvOuSQ-S"
   },
   "source": [
    "Using the profiling tools demonstrated above:\n",
    "\n",
    "* Use timeit to calculate how long the function takes to run with the `very_long_integer`\n",
    "* Use lprun to determine how long the code spends at each line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CmkB68KnSQ-S"
   },
   "outputs": [],
   "source": [
    "# Run timeit and lprun here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNFKeSdOSQ-S"
   },
   "source": [
    "Here is the optimized code that we used last year (with the bug fixed). As before run timeit and lprof on this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cPrUVeVESQ-S"
   },
   "outputs": [],
   "source": [
    "def square_digits_withoutstr(input_number):\n",
    "\n",
    "    cur = input_number\n",
    "    was = set()\n",
    "\n",
    "    while not (cur in was):\n",
    "        was.add(cur)\n",
    "        nxt = 0\n",
    "        while cur > 0:\n",
    "            nxt += (cur % 10) * (cur % 10)\n",
    "            cur //= 10\n",
    "        cur = nxt\n",
    "\n",
    "    return len(was) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ZBCTFmeSQ-S"
   },
   "outputs": [],
   "source": [
    "# Run timeit and lprun here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQtARBJ9SQ-S"
   },
   "source": [
    "Now repeat the process using:\n",
    "```very_long_integer=2**100000```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jyQvNb_hSQ-S",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run timeit and lprun here\n",
    "\n",
    "very_long_integer = 2**100000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m72QVXwqSQ-S"
   },
   "source": [
    "### Exercise 2 - Summary\n",
    "\n",
    "Think about what these results are telling you. Some things to highlight:\n",
    "\n",
    "* You are learning how to identify which parts of a function you need to think about when optimising. Never bother optimising any part of your code that is not taking a significant fraction of the total time.\n",
    "* The optimal solution to a problem can depend on the input. For shorter inputs, converting an integer to a string and then back to a list of integers adds an overhead that is the dominant computational cost. However, as the input integers become very large, operations like dividing by 10 (which for a computer is not as trivial as it seems, because computers think in binary numbers, not base-10 numbers) become expensive (look up how python handles big integers if you want to understand this better). In this case the overhead of converting to a string is faster.\n",
    "* Although the second case was faster for normal-sized integers, it doesn't seem that using it would really be a good decision if the code is more difficult to parse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "heX-KFasSQ-S"
   },
   "source": [
    "## Exercise 3 - Identifying common elements in two large lists\n",
    "\n",
    "\n",
    "This interactive example demonstrates that is often important to use the right tool, or computational method, for the task at hand. \n",
    "\n",
    "An example of this is the problem I set the first years earlier this year:\n",
    "\n",
    "Write a function numpy_nested_sum, which takes as input two 1D numpy arrays (x and y) with lengths N and M respectively and computes the following sum:\n",
    "\n",
    "$\\sum_{i=0}^{N-1} \\sum_{j=0}^{M-1} \\left(x[i]^2 + y[j]^2 \\right)$\n",
    "\n",
    "Many of the students tried something like\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sum(arrx, arry):\n",
    "    summ = 0\n",
    "    for i in range(len(arrx)):\n",
    "        for j in range(len(arry)):\n",
    "            summ += arrx[i]**2 + arry[i]**2\n",
    "    return summ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This directly implements the question as written, but didn't pass the longest test case (due to timeout). Those students that remembered that they were also highly trained mathemeticians did some algebraic reordering and realised that this was equal to:\n",
    "\n",
    "$\\sum_{i=0}^{N-1} (M * x[i]^2) +  \\sum_{j=0}^{M-1} ( N * y[j]^2)$\n",
    "\n",
    "This is then coded as\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sum(arrx, arry):\n",
    "    summ = 0\n",
    "    for i in range(len(arrx)):\n",
    "        summ += M * arrx[i]**2\n",
    "    \n",
    "    for j in range(len(arry)):\n",
    "        summ += N * arry[i]**2\n",
    "    return summ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the students got full marks. The hint in the function name (to call this *nested* sum), was a bit unfair of course. However, the principal here is the important one: How many operations do you actually need to do to get the necessary output? This is called \"complexity analysis\" in computing, this article has a lot more details on this:\n",
    "\n",
    "https://www.freecodecamp.org/news/big-o-notation-why-it-matters-and-why-it-doesnt-1674cfa8a23c/\n",
    "\n",
    "\n",
    "Let's consider a different problem:\n",
    "\n",
    "* Consider two large lists of integers. Identify integers which are in *both* lists\n",
    "\n",
    "First let's create the lists and then let's take a first stab at this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z2ND9s8OSQ-S"
   },
   "outputs": [],
   "source": [
    "# Let's create our lists first - DO NOT change this code\n",
    "import numpy\n",
    "list_a = numpy.random.randint(0,10000000,size=[100000])\n",
    "list_b = numpy.random.randint(0,10000000,size=[100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dJlXCdxgSQ-T"
   },
   "outputs": [],
   "source": [
    "# Then let's write our first solution\n",
    "def identify_common_elements(list_1, list_2):\n",
    "    common_elements = []\n",
    "    # Let's just write a for loop, and for every element check if it's in list_2\n",
    "    for elem in list_1:\n",
    "        if elem in list_2:\n",
    "            common_elements.append(elem)\n",
    "    return common_elements\n",
    "\n",
    "# This seems like it should be fast, right??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bfi_WgCsSQ-T"
   },
   "source": [
    "As before, run timeit and lprof on this code to determine run-time and the slowest line. *Before* running lprof identify where you think the most time will be taken, in which line of the code. Were you right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qjzpYDv5SQ-T"
   },
   "outputs": [],
   "source": [
    "# Run timeit and lprun here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tnVdL610SQ-T"
   },
   "source": [
    "Most of the time is spent determining if elem is in list 2, for every element. There are in total `O(N**2)` operations in this operation, where N is the length of the array. Specifically for each of the `N` elements in list 1 we have to check if any of the `N` elements in list 2 are the same. (There would be some special cases here, for example if the lists have a length of 1000000, but contained only integers between 0 and 10). \n",
    "\n",
    "Can we do better? How can we speed up the `elem in list_2` part of the code? How about this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CIsjyjy9SQ-T"
   },
   "outputs": [],
   "source": [
    "# Let's try that again\n",
    "def identify_common_elements_with_a_set(list_1, list_2):\n",
    "    # ALL I DO IS ADD THE FOLLOWING 1 LINE\n",
    "    list_2 = set(list_2)\n",
    "    common_elements = []\n",
    "    # Let's just write a for loop, and for every element check if it's in list_2\n",
    "    for elem in list_1:\n",
    "        if elem in list_2:\n",
    "            common_elements.append(elem)\n",
    "    return common_elements\n",
    "\n",
    "# This seems like it wouldn't be any faster, right??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wn7gSGwESQ-T"
   },
   "source": [
    "Again use timeit and lprof to profile the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DsD_tzn7SQ-T"
   },
   "outputs": [],
   "source": [
    "# Run timeit and lprun here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kBm9qPjHSQ-T"
   },
   "source": [
    "Think about why that happened?\n",
    "\n",
    "Sometimes optimisations in python aren't obvious, because a lot of the internal details can be hidden. A `set` and a `list` are similar but very different objects. On the face of it a `set` just contains a list of non-duplicated entries (So `set([1,1,2,3,4])` = `set([1,2,3,4])`). But because non-duplicate entries are not possible the set can check if an item is in the `set`*much* more quickly than you can check if an item is in a list ... Basically python implements a technique called a \"hash table\" https://en.wikipedia.org/wiki/Hash_table to decide quickly if an object is already in the set. Dictionaries use the same technique with their keys. (Also look up binary search tables as another interesting technique for this kind of thing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tPEYdcBGSQ-T"
   },
   "outputs": [],
   "source": [
    "# One more try\n",
    "def identify_common_elements_with_two_sets(list_1, list_2):\n",
    "    list_1 = set(list_1)\n",
    "    list_2 = set(list_2)\n",
    "    return list(list_1 & list_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iM4yk7XgSQ-T"
   },
   "source": [
    "Again profile this code, is it quicker than the previous version?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VNbAx-R2SQ-T"
   },
   "outputs": [],
   "source": [
    "# Run timeit and lprun here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uimrWJtsSQ-T"
   },
   "source": [
    "You can use the `&` operator to take the combination of the two lists. This results in a code with much fewer lines, but the overall cost is much the same. *Converting* a list to a set would be a non-negligible cost here, but if your input is already a set, and your output can be a set then this operation will be faster.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xtUI4LbGSQ-T",
    "outputId": "8a46203e-3dcc-4f7a-a8b5-ce4a07630fb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.12 ms ± 16.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "set_a = set(list_a)\n",
    "set_b = set(list_b)\n",
    "%timeit set_a & set_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tptydkNlSQ-T"
   },
   "source": [
    "Can we do even better and record integers that occur multiple times in both lists? This algorithm sorts the input and then walks through the sorted arrays looking for duplicates. The sorting is a `N log N` operation, and the walkthrough requires `O(N)` operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l-HR3d1tSQ-T"
   },
   "outputs": [],
   "source": [
    "# Let's try that again\n",
    "def identify_common_elements_with_a_walk(list_1, list_2):\n",
    "    list_1 = sorted(list_1)\n",
    "    list_2 = sorted(list_2)\n",
    "    idx_1 = 0\n",
    "    idx_2 = 0\n",
    "    l1 = len(list_1)\n",
    "    l2 = len(list_2)\n",
    "    common_elements = []\n",
    "    curr_1 = list_1[idx_1]\n",
    "    curr_2 = list_2[idx_2]\n",
    "    while 1:\n",
    "        if curr_1 == curr_2:\n",
    "            common_elements.append(curr_1)\n",
    "            idx_1 += 1\n",
    "            if idx_1 == l1:\n",
    "                break\n",
    "            curr_1 = list_1[idx_1]\n",
    "            idx_2 += 1\n",
    "            if idx_2 == l2:\n",
    "                break\n",
    "            curr_2 = list_2[idx_2]\n",
    "        elif curr_1 < curr_2:\n",
    "            idx_1 += 1\n",
    "            if idx_1 == l1:\n",
    "                break\n",
    "            curr_1 = list_1[idx_1]\n",
    "        else:\n",
    "            idx_2 += 1\n",
    "            if idx_2 == l2:\n",
    "                break\n",
    "            curr_2 = list_2[idx_2]\n",
    "    return common_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PxIuEUz8SQ-T"
   },
   "outputs": [],
   "source": [
    "# Run timeit and lprun here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kfz6kU4wSQ-T"
   },
   "source": [
    "For the data arrays we are considering this is not faster, even if the arrays are sorted before sending to the function. That's probably not surprising. The `&` method on the two sets would have implemented this if it were faster!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GV-xK34GSQ-T"
   },
   "source": [
    "## Exercise 4 - Sorting an array\n",
    "\n",
    "Sorting arrays is a common operation. Making a sorting algorithm that is *fast* is very important and there are many different approaches to the problem (python, for example uses \"Timsort\"):\n",
    "\n",
    "https://en.wikipedia.org/wiki/Sorting_algorithm\n",
    "\n",
    "There is a rule though: If you have an array that contains random input, then you will require an average of `O(N log(N))` operations to sort the array. If the array is *not* random though, this can be shorter (e.g. if the array is already sorted, this can be done in `O(N)`, which is the cost required to identify that the array *is* sorted.\n",
    "\n",
    "As this is the last exercise, let's make this challenging:\n",
    "\n",
    "* Write your own code that will take as input an array of numbers. Return a sorted *copy* of the array (the original array should be unchanged). Don't worry too much about making the code fast until you have something that works. When you have something that works, see how you can use the tools presented above to make it as fast as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zqHcoxfbSQ-T"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "def sort_array(unsorted_array):\n",
    "    # This line will copy the array so that the input will be preserved.\n",
    "    # After this you can do what you want to unsorted_array\n",
    "    unsorted_array = copy.deepcopy(unsorted_array)\n",
    "    \n",
    "    # FIXME: You need to fill this with code DO NOT use python's built-in sort/sorted routines (or any link to\n",
    "    # that e.g. numpy.sorted). The problem is to think about how you would do this!\n",
    "    \n",
    "    return sorted_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bt51ADUESQ-T"
   },
   "outputs": [],
   "source": [
    "# Use this cell to profile your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmt15IH8SQ-U"
   },
   "source": [
    "How does your code compare with other code? Here's three examples of pre-existing sorting algorithms. The first is python's built-in `sort` routine:\n",
    "```\n",
    "sorted_array = sorted(unsorted_array)\n",
    "```\n",
    "The next three functions are implications of\n",
    "* The \"quicksort\" technique\n",
    "* The \"mergsort\" technique\n",
    "* The \"bubblesort\" technique\n",
    "\n",
    "See here for a description of each of these\n",
    "\n",
    "https://app.codesignal.com/interview-practice/topics/sorting/tutorial\n",
    "\n",
    "or here\n",
    "\n",
    "https://en.wikipedia.org/wiki/Sorting_algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x3Yqbl7RSQ-U"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "def quick_sort(a, l=None, r=None, copied=False):\n",
    "    if not copied:\n",
    "        a = copy.deepcopy(a)\n",
    "    if l is None:\n",
    "        l = 0\n",
    "    if r is None:\n",
    "        r = len(a) - 1\n",
    "    if l >= r:\n",
    "        return a\n",
    "\n",
    "    x = a[l]\n",
    "    i = l\n",
    "    j = r\n",
    "\n",
    "    while i <= j:\n",
    "        while a[i] < x:\n",
    "            i += 1\n",
    "        while a[j] > x:\n",
    "            j -= 1\n",
    "        if i <= j:\n",
    "            t = a[i]\n",
    "            a[i] = a[j]\n",
    "            a[j] = t\n",
    "            i += 1\n",
    "            j -= 1\n",
    "    \n",
    "    # This is an example of a recursive program. Where we call a function from within the *same* function with a\n",
    "    # reduced scope. However, this will make profiling hard!\n",
    "    if (i-1-l) >= 1:\n",
    "        quick_sort(a, l=l, r=i-1, copied=True)\n",
    "    if (r-i) >= 1:\n",
    "        quick_sort(a, l=i, r=r, copied=True)\n",
    "\n",
    "    return a\n",
    "\n",
    "\n",
    "def merge_sort(sequence):\n",
    "    sequence = copy.deepcopy(sequence)\n",
    "    \n",
    "    def merge(sequence, left, middle, right):\n",
    "\n",
    "        result = []\n",
    "\n",
    "        i = left\n",
    "        j = middle\n",
    "        while i < middle and j < right:\n",
    "            if sequence[i] < sequence[j]:\n",
    "                result.append(sequence[i])\n",
    "                i += 1\n",
    "            else:\n",
    "                result.append(sequence[j])\n",
    "                j += 1\n",
    "\n",
    "        while i < middle:\n",
    "            result.append(sequence[i])\n",
    "            i += 1\n",
    "\n",
    "        while j < right:\n",
    "            result.append(sequence[j])\n",
    "            j += 1\n",
    "\n",
    "        for i in range(left, right):\n",
    "            sequence[i] = result[i - left]\n",
    "\n",
    "    def split(sequence, left, right):\n",
    "        middle = (left + right) // 2\n",
    "\n",
    "        if right - left < 2:\n",
    "            return\n",
    "        split(sequence, left, middle)\n",
    "        split(sequence, middle, right)\n",
    "        merge(sequence, left, middle, right)\n",
    "\n",
    "    split(sequence, 0, len(sequence))\n",
    "\n",
    "    return sequence\n",
    "\n",
    "def bubble_sort(items):\n",
    "    items = copy.deepcopy(items)\n",
    "\n",
    "    def swap(firstIndex, secondIndex):\n",
    "        temp = items[firstIndex]\n",
    "        items[firstIndex] = items[secondIndex]\n",
    "        items[secondIndex] = temp\n",
    "\n",
    "    length = len(items)\n",
    "\n",
    "    stop = length - 1\n",
    "    while stop > 0:\n",
    "        j = 0\n",
    "        last_swap = 0\n",
    "        while j < stop:\n",
    "            if items[j] > items[j + 1]:\n",
    "                swap(j, j + 1)\n",
    "                last_swap = j\n",
    "            j += 1\n",
    "        stop = last_swap\n",
    "    return items\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07HBccsySQ-U"
   },
   "source": [
    "For each of the arrays below, time how long it takes to sort the array with each of the methods above, including your own function and the built-in `sorted` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PJ6vkGmgSQ-U"
   },
   "outputs": [],
   "source": [
    "# Array of random numbers\n",
    "array_a = numpy.random.randint(0,100,size=1000)\n",
    "# An already sorted array\n",
    "array_b = numpy.arange(1000)\n",
    "# An *inversely* sorted array\n",
    "array_c = numpy.arange(1000)[::-1]\n",
    "# Two sorted arrays appended together\n",
    "array_d = numpy.append(numpy.arange(500),numpy.arange(500))\n",
    "\n",
    "# Time the various sorting algorithms below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijkX01C4SQ-U"
   },
   "source": [
    "## Acknowledgements\n",
    "\n",
    "With thanks to the following\n",
    "\n",
    "* https://ipython-books.github.io\n",
    "* https://jakevdp.github.io/PythonDataScienceHandbook\n",
    "* https://app.codesignal.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ukVZ_PkSQ-U"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
