{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b89069a",
   "metadata": {},
   "source": [
    "# A long(ish) example showing how to optimize a numerical integration code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af46442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install line_profiler\n",
    "!{sys.executable} -m pip install memory_profiler\n",
    "\n",
    "%load_ext line_profiler\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40880b06",
   "metadata": {},
   "source": [
    "\n",
    "Here's some example code which integrates\n",
    "\n",
    "$cos(x) \\times \\frac{1}{x} $\n",
    "\n",
    "from $x = 1$ to $x=1000$.\n",
    "\n",
    "We will do this by using the simple rectangular method for numerically integrating. https://en.wikipedia.org/wiki/Riemann_sum .... I know you all know the theory behind this, and how to code up such an example, as I taught it to you all in MATLAB last year!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bfbd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: We write this as a set of functions. Functions are better to isolate different parts of\n",
    "#       the code and to be able to check each component individually. Using a class and class methods\n",
    "#       to do this is also fine, and we mix both here to show this ... Might not be the most aesthetic\n",
    "#       way of doing this, though! However, this does serve as a reminder: Don't write long blocks of code\n",
    "#       split up into functions!\n",
    "import numpy\n",
    "import math\n",
    "\n",
    "def compute_cosx(tseries):\n",
    "    \"\"\"\n",
    "    Computes cos(t) for all values in tseries\n",
    "    \"\"\"\n",
    "    cosx = numpy.zeros(len(tseries))\n",
    "    for idx, tval in enumerate(tseries):\n",
    "        cosx[idx] = math.cos(tseries[idx])\n",
    "    return cosx\n",
    "\n",
    "def compute_invx(tseries):\n",
    "    \"\"\"\n",
    "    Computes 1/x for all values in tseries\n",
    "    \"\"\"\n",
    "    invx = numpy.zeros(len(tseries))\n",
    "    for idx, tval in enumerate(tseries):\n",
    "        invx[idx] = 1 / tseries[idx]\n",
    "    return invx\n",
    "\n",
    "def compute_seriesproduct(series1, series2):\n",
    "    \"\"\"\n",
    "    Multiplies each element in series1 with the corresponding element in series2.\n",
    "    This returns an array of the multiplied elements.\n",
    "    \"\"\"\n",
    "    # Ensure the two arrays are the same length\n",
    "    assert(len(series1)==len(series2))\n",
    "    seriessum = numpy.zeros(len(series1))\n",
    "    for idx in range(len(series1)):\n",
    "        seriessum[idx] = series1[idx] * series2[idx]\n",
    "    return seriessum\n",
    "\n",
    "def compute_seriessum(series):\n",
    "    \"\"\"\n",
    "    Computes the sum of all values in series\n",
    "    \"\"\"\n",
    "    sumvals = 0\n",
    "    for idx in range(len(series)):\n",
    "        sumvals = sumvals + series[idx]\n",
    "    return sumvals\n",
    "\n",
    "\n",
    "class Integrator():  \n",
    "    def generate_integral(self):\n",
    "        \"\"\"\n",
    "        Integral function goes here\n",
    "        \"\"\"\n",
    "        cosx = compute_cosx(self.tseries)\n",
    "        invx = compute_invx(self.tseries)\n",
    "        prod = compute_seriesproduct(cosx, invx)\n",
    "        summed_prod = compute_seriessum(prod)\n",
    "        return summed_prod * self.delta_t\n",
    "\n",
    "\n",
    "    def __init__(self, tmin, tmax, delta_t):\n",
    "        \"\"\"\n",
    "        Initializes the class and timeseries\n",
    "        \"\"\"\n",
    "        self.tmin = tmin\n",
    "        self.tmax = tmax\n",
    "        self.delta_t = delta_t\n",
    "        tseries = numpy.arange(self.tmin, self.tmax, self.delta_t)\n",
    "        # We shift tseries by delta_t / 2 to ensure that we are using the midpoint rule (see wikipedia page)\n",
    "        tseries = tseries + self.delta_t / 2.\n",
    "        self.tseries = tseries\n",
    "\n",
    "\n",
    "def main_function():\n",
    "    intgr = Integrator(1, 10000, 1./300.)\n",
    "    return intgr.generate_integral()\n",
    "\n",
    "print (main_function())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58aaab2",
   "metadata": {},
   "source": [
    "## Starting to understand the speed/optimality of the code\n",
    "\n",
    "Our first step in understanding the code is to time it. This can be done in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871f7670",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit main_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089b894d",
   "metadata": {},
   "source": [
    "Timeit will run the code a number of times and take an average. How many times it runs the code depends on how long the code takes (though you can override these values). Here we can see that our code took approximately a second to run. If running this only once then this is of course trivial.\n",
    "\n",
    "**Important rule of optimising: Don't waste time optimising a block of code, unless it is slowing down your work ... If others are using your code, you must think about how they might use your code though, might it be a problem in the future? There are certainly some things in the code above that are unnecessarily slow, which can be made faster just by writing the code better in the first place**\n",
    "\n",
    "Let's assume though that we might need to run this code thousands of times (or hundreds of thousands of times). In that case let's see what we can do to make it faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2e914d",
   "metadata": {},
   "source": [
    "## Profiling code\n",
    "\n",
    "Python and Jupyter notebooks have some neat tools for profiling code. Profiling means measuring how long the code takes to run individual blocks of code. Most profilers measure the fraction of time spent inside each individual *function*. Therefore splitting your code up into a number of different functions can help both in terms of making it easier to read and understand the code, but also in terms of understanding any bottlenecks.\n",
    "\n",
    "Below we run a built-in profiler on our code above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85200da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%prun -l 10 -q -T prun0 main_function()\n",
    "\n",
    "print(open('prun0', 'r').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47c6044",
   "metadata": {},
   "source": [
    "The `tottime` entry is the amount of time spent within each function. We can see that the majority of time is spent computing `cos(x)`, `inv(x)` and doing the series product and sum.\n",
    "\n",
    "To introduce all of our profiling tools in one place, let's also look at line-by-line and memory profiling. We can use the following to run the code to produce line-by-line profiling information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9fb782",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = numpy.arange(1.0,1000.,0.01)\n",
    "#compute_cosx(timeseries)\n",
    "\n",
    "%lprun -T lprof0 -f main_function main_function()\n",
    "\n",
    "print(open('lprof0', 'r').read())\n",
    "\n",
    "# And we can also profile the sub-functions, such as compute_cosx\n",
    "\n",
    "%lprun -T lprof0 -f compute_cosx compute_cosx(timeseries)\n",
    "\n",
    "print(open('lprof0', 'r').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd9de48",
   "metadata": {},
   "source": [
    "Finally, although we will not use it in this class, we can also profile the *memory usage* of a function in the same way. Unfortunately this only works for functions written in an external file, so we need to dump our code to a file and then run it from the file. Here's an example of that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a142d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file mprun_demo.py\n",
    "import numpy\n",
    "def invx_demo(tseries):\n",
    "    \"\"\"\n",
    "    Computes 1/x for all values in tseries\n",
    "    \"\"\"\n",
    "    invx = 1 / tseries\n",
    "    return invx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09482aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mprun_demo import invx_demo\n",
    "timeseries = numpy.arange(1.0,10000.,0.01)\n",
    "\n",
    "%mprun -f invx_demo invx_demo(timeseries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858992a4",
   "metadata": {},
   "source": [
    "## Using these tools and information to speed things up\n",
    "\n",
    "Okay, now that we've understood the tools available to us. Let's try to see if we can't improve things. The first place where the code is slow is in the `compute_cosx` function. Here's a major rule in python optimization:\n",
    "\n",
    "* Avoid for loops wherever possible\n",
    "\n",
    "In this case rather than using a python for loop to compute `cos(x)` at every index, let's use numpy to compute it at all indexes in one call. Yes, internally it will still need to loop over all values of `x` at some point and compute `cos(x)` for each point, but this will happen deep in some compiled numpy routine. In short\n",
    "\n",
    "* Use numpy routines on vectors to avoid for loops where possible.\n",
    "\n",
    "So we can replace our `compute_cosx` function with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1f1b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosx(tseries):\n",
    "    \"\"\"\n",
    "    Computes cos(t) for all values in tseries\n",
    "    \"\"\"\n",
    "    return numpy.cos(tseries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aba252f",
   "metadata": {},
   "source": [
    "Note that running this *after* the block above just replaces this function, so we can just run our profiler again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40633358",
   "metadata": {},
   "outputs": [],
   "source": [
    "%prun -l 10 -q -T prun0 main_function()\n",
    "\n",
    "print(open('prun0', 'r').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce21a2ab",
   "metadata": {},
   "source": [
    "Now we can see that quite a bit of time is being spent in the remaining 3 `compute_x` functions. Let's try optimizing these as well by replacing the for loops with numpy vectorized calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75485b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_invx(tseries):\n",
    "    \"\"\"\n",
    "    Computes 1/x for all values in tseries\n",
    "    \"\"\"\n",
    "    return 1. / tseries\n",
    "\n",
    "def compute_seriesproduct(series1, series2):\n",
    "    \"\"\"\n",
    "    Multiplies each element in series1 with the corresponding element in series2.\n",
    "    This returns an array of the multiplied elements.\n",
    "    \"\"\"\n",
    "    # Ensure the two arrays are the same length\n",
    "    assert(len(series1)==len(series2))\n",
    "    return series1 * series2\n",
    "\n",
    "def compute_seriessum(series):\n",
    "    \"\"\"\n",
    "    Computes the sum of all values in series\n",
    "    \"\"\"\n",
    "    return series.sum()\n",
    "\n",
    "%prun -l 10 -q -T prun0 main_function()\n",
    "\n",
    "print(open('prun0', 'r').read())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f073a88",
   "metadata": {},
   "source": [
    "The code is now limited be a vectorized computation of cos(x). Not easy to make that much faster! Now with these optimizations let's see how fast our code runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37025714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please note: The times shown here, and on the functions above are based on Ian's ARM macbook.\n",
    "# That is a very different machine to the standard Colab/SciServer virtualmachines you will be running on.\n",
    "# Expect my macbook to be faster, and to perhaps have different performance gains!!\n",
    "\n",
    "%timeit main_function()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
